#!/bin/env python

import sys, os, glob, re, argparse
import datetime as dt
import random

#sys.path.append('/home/fmcnally/npx4')
from npx4.pysubmit import pysubmit

""" 
INSTRUCTIONS: before executing, change hardcoded paths anywhere you see 
the word 'CHANGE'.
"""


def getDSTfiles(config):

    fpath = '/data/user/gbratrud/dst_data'
    fileList = glob.glob('{}/*.root'.format(fpath))
    # Newer years have part files nested in daily folders
    if fileList == []:
        fileList = glob.glob('{}/*/*.root'.format(fpath))
    return sorted(fileList)

## Special cases for binning in energy. Calling the flag
## without values will default to the listed values.
class defaultValues(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        bins = {}
        bins['ebins'] = [4, 4.25, 4.5, 4.75, 5, 5.25, 5.5, 6, 6.5, 100]
        if not values:
            setattr(namespace, self.dest, bins[self.dest])
        else:
            setattr(namespace, self.dest, values)


if __name__ == "__main__":

    p = argparse.ArgumentParser(
            description='Makes daily healpix maps using time-scrambling code')

    # General parameters
    p.add_argument('-c', '--config', dest='config',
            help='Detector configuration [IC86-2011,IC86-2012,IC86-2013...]')
    p.add_argument('-d', '--dates', dest='dates', type=str,
            default=None, nargs='*',
            help='Dates to process [yyyymmdd] (optional, inclusive)')
    p.add_argument('-i', '--inclusive', dest='inclusive',
            default=False, action='store_true',
            help='Treat two dates given as inclusive. Otherwise treat as list')
    p.add_argument('--sd', dest='sundp',
            default=False, action='store_true',
            help='Correct for solar dipole on event-by-event basis')

    # Energy cut options
    p.add_argument('--ebins', dest='ebins',
            default=False, action=defaultValues, nargs='*',
            help='Option to do all energy bins')

    # Additional options
    p.add_argument('-o', '--outdir', dest='outdir',
            # CHANGE: suggested path: /data/user/[username]/maps
            default='@CRA_BUILD@/maps',
            help='Destination directory for output files')
    p.add_argument('--test', dest='test',
            default=False, action='store_true',
            help='Option for running off cluster to test')
    p.add_argument('--overwrite', dest='overwrite',
            default=False, action='store_true',
            help='Option to overwrite existing map files')
    p.add_argument('--splinepath', dest='splinepath',
            default=None,
            help='Path to spline files')
    p.add_argument('--cvmfs', dest='cvmfs',
            default='@CVMFS_SROOTBASE@',
            help='CVMFS environment')
    p.add_argument('--submit_dir', dest='submit_dir',
            default='@CRA_BUILD@/submit-dir',
            help='submit directory')
    p.add_argument('--smax', dest='smax',
            default=0.0,
            help='max STA8')
    p.add_argument('--smin', dest='smin',
            default=0.0,
            help='min STA8')
    p.add_argument('--nside', dest='nsideout',
            default=64,
            help='Healpix NSide parameter')
    p.add_argument('--condor-priority', dest='priority',
            default=1, 
            help='Job priority in condor')
    ### USER-SPECIFIC PATHS (CHANGE) ###
    """ These paths all refer to directories. Make sure you create your
    own directories as needed """
    # Submitter capable of submitting multiple days as one job, w/
    # TimeScramble.cc reading filelist from .txt file.
    #  - determines .txt file location (can remove after jobs run) 
    

    args = p.parse_args()
    c_opts = vars(args).copy()
    if not args.config:
        p.error('Detector configuration not given')


    # Default spline files
    c_opts['spline'] = args.splinepath

    # Base name for outfiles
    outBase = '{outdir}/{config}'.format(**c_opts)
    if args.sundp:
       outBase += '_sd'
    c_opts['outBase'] = outBase

    # Create output directories if they don't already exist
    if not os.path.isdir('{outBase}'.format(**c_opts)):
        print('Creating output directory {outBase}'.format(**c_opts))
        os.makedirs('{outBase}'.format(**c_opts))

    # Create list of desired dates
    runDates = []
    if args.dates != None and not args.inclusive:
        runDates = ['{}-{}-{}'.format(d[:4],d[4:6],d[6:8]) for d in args.dates]
    if args.dates != None and args.inclusive:
        s = args.dates[0]
        e = args.dates[-1]
        sdate = dt.date(int(s[:4]), int(s[4:6]), int(s[6:8]))
        edate = dt.date(int(e[:4]), int(e[4:6]), int(e[6:8]))
        delta = edate - sdate
        runDates = [sdate + dt.timedelta(days=i) for i in range(delta.days+1)]
        runDates = [date.strftime('%Y-%m-%d') for date in runDates]

    # Collect input files
    fileList = []
    masterList = getDSTfiles(args.config)
    for rootFile in masterList:

        # Filter by desired dates
        date = re.findall('_year_\d{4}_\d{4}', rootFile)[-1]
        dt_obj = dt.datetime.strptime(date, '_year_%Y_%m%d')
        date = dt_obj.strftime('%Y-%m-%d')
        if (args.dates != None) and (date not in runDates):
            continue
        print(date,rootFile)

        # Apply naming conventions to find existing files
        testFiles = [outBase]
        if args.ebins:
            testFiles = ['%s_%s-%sGeV' % (f, args.ebins[i], args.ebins[i+1]) \
                    for i in range(len(args.ebins)-1) for f in testFiles]
        testFiles = ['%s_%s.fits' % (f, date) for f in testFiles]

        # Overwrite or omit existing files
        # Files for bins are all created at once - only omit if all exist
        if all([os.path.isfile(f) for f in testFiles]) and not args.overwrite:
            continue
        for testFile in testFiles:
            if os.path.isfile(testFile):
                os.remove(testFile)

        fileList.append(rootFile)

    # Split into days for submission
    dateList = [re.findall('_year_\d{4}_\d{4}',  f)[-1] for f in fileList]
    dateList = [dt.datetime.strptime(date, '_year_%Y_%m%d') for date in dateList]
    dateList = sorted(list(set(dateList)))  # Limit to unique values

    # Collect surrounding files to allow runs from midnight to midnight
    # ("Daily" files grouped by run, not actually 24 hours)
    dayFiles = []
    for day in dateList:
        dayFiles += [[f for f in masterList if (day.strftime('_year_%Y_%m%d') in f) ]]

    dayFiles = [' '.join(oneDay)+'\n' for oneDay in dayFiles]
    if args.test:
        dayFiles = dayFiles[:1]
        dateList = dateList[:1]

    # Set up parameters to feed C++ script
    print('Parameters for submission:')
    validArgs  = ['config','smax','smin','nsideout']
    c_opts = {k:v for k,v in c_opts.items() if v!=None and k in validArgs}
    for key in sorted(c_opts.keys()):
        print('  --%s %s' % (key, c_opts[key]))
    c_opts = [['--'+key, c_opts[key]] for key in sorted(c_opts.keys())]
    # Python magic: flatten list of arbitrary depth into list of strings
    flatList = lambda *n: (str(e) for a in n \
            for e in (flatList(*a) if isinstance(a, (tuple, list)) else (a,)))
    c_opts = ' '.join(list(flatList(c_opts)))
    # Ebins need to go last (multitoken parameters)
    if args.sundp:
        print('  --sundp')
        c_opts += ' --sundp'

    # Increase requested memory for jobs that produce multiple maps
    ## NOTE: exceeded memory limit (1000 MB) with single day.
    ## Don't remember this being a problem, changing from double to float
    ## does *not* fix it :(
    ## Appears to cap out around 2500 MB
    sublines = ["request_memory = 3000"]
    if args.ebins:
        sublines = ["request_memory = 6000"]

    # Environment for script
    header = ['#!/bin/bash ']
    if args.cvmfs:
        header = ['#!/bin/sh','eval `' +args.cvmfs +'/setup.sh`']

    # Submit files
    print('Submitting %i files...' % len(dayFiles))
    if not os.path.isdir(args.submit_dir):
        os.makedirs(args.submit_dir)
    for i in range(len(dayFiles)):

        jobID = 'makelocalmaps_%s_%05i_%05i' % (args.config, i, random.randint(0,99999))
        cmd  = '@CRA_BUILD@/bin/make-local-maps' 
        subdir = dateList[i].strftime('%Y-%m-%d')
        ex = [cmd, c_opts,'--outdir','{}/{}'.format(outBase,subdir), '--input', dayFiles[i] ]
        ex = ' '.join(ex)
        print(ex)
        print('')
        os.makedirs('{}/{}'.format(outBase,dateList[i]))
        pysubmit(ex, sublines=sublines, test=args.test, jobID=jobID,
                outdir=args.submit_dir,
                header=header,
                priority=args.priority,
                condor_dag='{}/{}.make-local-maps.dag'.format(args.submit_dir,args.config)
                )
